{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70819aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Setup di base (CML) ======\n",
    "import cml.data_v1 as cmldata\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os, re\n",
    "\n",
    "# Usa la connection del workspace (chiedi all'admin il nome esatto se diverso)\n",
    "CONNECTION_NAME = \"pdnd-prod-dl-1\"\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark: SparkSession = conn.get_spark_session()\n",
    "print(\"Spark enabled:\", spark.version)\n",
    "\n",
    "# Un po' di \"igiene\" per ridurre l'impatto\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"64\")  # abbassa shuffles\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")  # evita errori Arrow\n",
    "\n",
    "# ====== Parametri facili da toccare ======\n",
    "DATE_FROM        = \"2025-01-01 00:00:00\"  # filtro data minimo\n",
    "TRANSFER_CAT_LIKE= \"%0101100IM%\"          # macro categoria\n",
    "SAMPLE_FRACTION  = 0.05                    # 5% random sample lato Spark (None per disattivare)\n",
    "MAX_ROWS         = 100_000                 # limite hard (0 o None = nessun limite, sconsigliato in CML)\n",
    "SHOW_ROWS        = 10                      # righe da mostrare di esempio\n",
    "\n",
    "# Dove salvare i CSV localmente nel progetto CML\n",
    "OUT_DIR = \"./artifacts\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f758bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "  t.fiscalcodepa        AS pa,\n",
    "  t.companyname         AS ragione_sociale,\n",
    "  t.remittanceinformation AS remittance\n",
    "FROM pagopa.silver_positive sp\n",
    "LATERAL VIEW EXPLODE(sp.transferlist) t_view AS t\n",
    "WHERE t.transfercategory LIKE '{TRANSFER_CAT_LIKE}'\n",
    "  AND sp.paymentinfo.paymentdatetime >= CAST('{DATE_FROM}' AS TIMESTAMP)\n",
    "  AND t.remittanceinformation IS NOT NULL\n",
    "  AND t.remittanceinformation <> ''\n",
    "\"\"\"\n",
    "\n",
    "print(\"Eseguo query Spark…\")\n",
    "df = spark.sql(query).select(\n",
    "    F.col(\"pa\").cast(\"string\"),\n",
    "    F.col(\"ragione_sociale\").cast(\"string\"),\n",
    "    F.col(\"remittance\").cast(\"string\")\n",
    ")\n",
    "\n",
    "# Campionamento e limite (per restare leggeri in CML)\n",
    "if SAMPLE_FRACTION:\n",
    "    df = df.sample(False, float(SAMPLE_FRACTION))\n",
    "if MAX_ROWS and int(MAX_ROWS) > 0:\n",
    "    df = df.limit(int(MAX_ROWS))\n",
    "\n",
    "df = df.cache()\n",
    "print(\"Conteggio (dopo sample/limit):\", df.count())\n",
    "df.show(SHOW_ROWS, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- a) Volumi per PA / ragione sociale (come la tua prima query)\n",
    "volumi = (df.groupBy(\"pa\", \"ragione_sociale\")\n",
    "            .agg(F.count(\"*\").alias(\"trx\"))\n",
    "            .orderBy(F.desc(\"trx\")))\n",
    "\n",
    "volumi.show(20, truncate=False)\n",
    "volumi.write.mode(\"overwrite\").option(\"header\",\"true\") \\\n",
    "    .csv(os.path.join(OUT_DIR, \"volumi_per_pa_csv\"))  # cartella con part file\n",
    "print(\"Volumi per PA: salvati in\", os.path.join(OUT_DIR, \"volumi_per_pa_csv\"))\n",
    "\n",
    "# --- b) Rule-based categories (facile da leggere, veloce)\n",
    "#     Usiamo regex in lower-case per intercettare varianti\n",
    "rem = F.lower(F.col(\"remittance\"))\n",
    "categoria = (\n",
    "    F.when(rem.rlike(r\".*(rateizz|rata|rateal).*\"), \"Rata\")\n",
    "     .when(rem.rlike(r\".*provvediment.*\"),          \"Provvedimento\")\n",
    "     .when(rem.rlike(r\".*accertament.*\"),           \"Accertamento\")\n",
    "     .when(rem.rlike(r\".*avvis.*\"),                 \"Avviso\")\n",
    "     .when(rem.rlike(r\".*fattur.*\"),                \"Fattura\")\n",
    "     .otherwise(\"Altro\")\n",
    ")\n",
    "\n",
    "cat_df = df.withColumn(\"categoria\", categoria)\n",
    "conteggi_cat = (cat_df.groupBy(\"categoria\").count().orderBy(F.desc(\"count\")))\n",
    "conteggi_cat.show(truncate=False)\n",
    "\n",
    "conteggi_cat.write.mode(\"overwrite\").option(\"header\",\"true\") \\\n",
    "    .csv(os.path.join(OUT_DIR, \"conteggi_categorie_csv\"))\n",
    "print(\"Conteggi categorie: salvati in\", os.path.join(OUT_DIR, \"conteggi_categorie_csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83895b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendiamo solo la colonna testuale\n",
    "text_spark = df.select(\"remittance\").dropna()\n",
    "\n",
    "# Per sicurezza, prendiamo un ulteriore mini campione per Pandas (es. 30k righe max)\n",
    "PANDAS_CAP = 30_000\n",
    "text_spark = text_spark.limit(PANDAS_CAP)\n",
    "\n",
    "print(\"Converto a Pandas…\")\n",
    "import pandas as pd\n",
    "text_pd = text_spark.toPandas()  # Arrow disabilitato sopra per evitare errori\n",
    "print(\"Righe Pandas:\", len(text_pd))\n",
    "text_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "\n",
    "# assicurati che questi pacchetti NLTK siano presenti (la prima volta servono i download)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "STOP_IT = set(stopwords.words('italian'))\n",
    "STEMMER = ItalianStemmer()\n",
    "\n",
    "punct_digits = re.compile(rf\"[{re.escape(string.punctuation)}0-9]+\")\n",
    "\n",
    "def preprocess(s: str, do_stem: bool = True) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = punct_digits.sub(\" \", s)\n",
    "    tokens = [t for t in s.split() if len(t) > 2 and t not in STOP_IT]\n",
    "    if do_stem:\n",
    "        tokens = [STEMMER.stem(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "text_pd[\"processed\"] = text_pd[\"remittance\"].map(preprocess)\n",
    "text_pd[\"processed\"].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=5)  # parametri prudenziali\n",
    "X = vectorizer.fit_transform(text_pd[\"processed\"])\n",
    "\n",
    "k = 8  # scegli tu, oppure fai il \"gomito\" su un campione più piccolo\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "labels = kmeans.fit_predict(X)\n",
    "text_pd[\"cluster\"] = labels\n",
    "\n",
    "print(\"Distribuzione cluster:\")\n",
    "print(text_pd[\"cluster\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409149e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "TOP_N = 10\n",
    "for i in range(k):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Cluster {i} | size={ (text_pd['cluster']==i).sum() }\")\n",
    "    print(\"Top terms:\", \", \".join(terms[order_centroids[i, :TOP_N]]))\n",
    "    # 3 esempi\n",
    "    samples = text_pd.loc[text_pd[\"cluster\"]==i, \"remittance\"].head(3).tolist()\n",
    "    for s in samples:\n",
    "        print(\"  -\", s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e12a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(OUT_DIR, \"remittance_clusters_sample.csv\")\n",
    "text_pd[[\"remittance\",\"processed\",\"cluster\"]].to_csv(csv_path, index=False)\n",
    "print(\"Clustering (sample) salvato in:\", csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
